id: ai_summary_workflow
namespace: ai.workflows

inputs:
  - id: consultation_id
    type: STRING
    required: true
    description: The consultation record ID from Supabase

  - id: callback_url
    type: STRING
    required: true
    description: Webhook URL to send the AI summary and doctor report back

variables:
  supabase_url: "https://hrwpsmgcgpkplkfxcurj.supabase.co"
  supabase_key: "REDACT_ME_IN_PROD" # move to Kestra Secrets
  openrouter_api_key: "REDACT_ME_IN_PROD" # move to Kestra Secrets
  webhook_secret_key: "jhbjbdjk4654hs"

tasks:
  # Task 1: Fetch consultation data from Supabase
  - id: fetch_consultation_data
    type: io.kestra.plugin.core.http.Request
    uri: "{{ vars.supabase_url }}/rest/v1/consultations"
    method: GET
    headers:
      apikey: "{{ vars.supabase_key }}"
      Authorization: "Bearer {{ vars.supabase_key }}"
      Content-Type: "application/json"
    contentType: application/json
    options:
      queryParameters:
        id: "eq.{{ inputs.consultation_id }}"
        select: "id,transcript,doctor_notes,appointment_id,appointment:appointments(id,doctor_id,patient_id,notes)"

  # Task 2: Extract consultation data
  - id: extract_data
    type: io.kestra.plugin.scripts.python.Script
    docker:
      image: python:3.11-slim
    env:
      CONSULTATION_DATA: "{{ outputs.fetch_consultation_data.body }}"
    script: |
      import os
      import json

      consultation_data = json.loads(os.environ["CONSULTATION_DATA"])
      
      if not consultation_data or len(consultation_data) == 0:
          raise ValueError("Consultation not found")
      
      consultation = consultation_data[0]
      
      # Extract data
      transcript = consultation.get("transcript", "")
      doctor_notes = consultation.get("doctor_notes", "")
      appointment = consultation.get("appointment", {})
      appointment_notes = appointment.get("notes", "") if appointment else ""
      
      # Save to files for next task
      with open("transcript.txt", "w", encoding="utf-8") as f:
          f.write(transcript or "No transcript available")
      
      with open("doctor_notes.txt", "w", encoding="utf-8") as f:
          f.write(doctor_notes or "No doctor notes available")
      
      with open("appointment_notes.txt", "w", encoding="utf-8") as f:
          f.write(appointment_notes or "No appointment notes available")
      
      print("Data extraction completed")
    outputFiles:
      - "transcript.txt"
      - "doctor_notes.txt"
      - "appointment_notes.txt"

  # Task 3: Generate AI Summary using OpenRouter
  - id: generate_ai_summary
    type: io.kestra.plugin.scripts.python.Script
    docker:
      image: python:3.11-slim
    env:
      OPENROUTER_API_KEY: "{{ vars.openrouter_api_key }}"
    inputFiles:
      transcript.txt: "{{ outputs.extract_data.outputFiles['transcript.txt'] }}"
      doctor_notes.txt: "{{ outputs.extract_data.outputFiles['doctor_notes.txt'] }}"
      appointment_notes.txt: "{{ outputs.extract_data.outputFiles['appointment_notes.txt'] }}"
    beforeCommands:
      - pip install openai
    script: |
      import os
      import json
      from openai import OpenAI

      # Initialize OpenRouter client (OpenAI-compatible API)
      client = OpenAI(
          api_key=os.environ["OPENROUTER_API_KEY"],
          base_url="https://openrouter.ai/api/v1"
      )

      # Read input files
      with open("transcript.txt", "r", encoding="utf-8") as f:
          transcript = f.read()
      
      with open("doctor_notes.txt", "r", encoding="utf-8") as f:
          doctor_notes = f.read()
      
      with open("appointment_notes.txt", "r", encoding="utf-8") as f:
          appointment_notes = f.read()

      # Create AI Summary prompt
      summary_prompt = f"""You are a medical AI assistant. Based on the following consultation information, generate a comprehensive medical consultation summary.

      CONSULTATION TRANSCRIPT:
      {transcript}

      DOCTOR'S NOTES:
      {doctor_notes}

      APPOINTMENT NOTES:
      {appointment_notes}

      Please provide a detailed consultation summary including:
      1. Chief Complaint
      2. Key Symptoms and History
      3. Examination Findings
      4. Diagnosis/Assessment
      5. Treatment Plan
      6. Follow-up Recommendations

      Format the summary in clear, professional medical language suitable for clinical records."""

      # Generate AI Summary
      summary_response = client.chat.completions.create(
          model="google/gemini-2.0-flash-exp:free",
          messages=[
              {"role": "system", "content": "You are a medical AI assistant specialized in creating clinical consultation summaries."},
              {"role": "user", "content": summary_prompt}
          ],
          temperature=0.3,
          max_tokens=2000
      )

      ai_summary = summary_response.choices[0].message.content

      # Save AI Summary
      with open("ai_summary.txt", "w", encoding="utf-8") as f:
          f.write(ai_summary)

      print("AI Summary generated successfully")
    outputFiles:
      - "ai_summary.txt"

  # Task 4: Generate Doctor Report
  - id: generate_doctor_report
    type: io.kestra.plugin.scripts.python.Script
    docker:
      image: python:3.11-slim
    env:
      OPENROUTER_API_KEY: "{{ vars.openrouter_api_key }}"
    inputFiles:
      transcript.txt: "{{ outputs.extract_data.outputFiles['transcript.txt'] }}"
      doctor_notes.txt: "{{ outputs.extract_data.outputFiles['doctor_notes.txt'] }}"
      appointment_notes.txt: "{{ outputs.extract_data.outputFiles['appointment_notes.txt'] }}"
      ai_summary.txt: "{{ outputs.generate_ai_summary.outputFiles['ai_summary.txt'] }}"
    beforeCommands:
      - pip install openai
    script: |
      import os
      import json
      from datetime import datetime
      from openai import OpenAI

      # Initialize OpenRouter client (OpenAI-compatible API)
      client = OpenAI(
          api_key=os.environ["OPENROUTER_API_KEY"],
          base_url="https://openrouter.ai/api/v1"
      )

      # Read input files
      with open("transcript.txt", "r", encoding="utf-8") as f:
          transcript = f.read()
      
      with open("doctor_notes.txt", "r", encoding="utf-8") as f:
          doctor_notes = f.read()
      
      with open("appointment_notes.txt", "r", encoding="utf-8") as f:
          appointment_notes = f.read()
      
      with open("ai_summary.txt", "r", encoding="utf-8") as f:
          ai_summary = f.read()

      # Create Doctor Report prompt
      report_prompt = f"""You are a medical AI assistant. Based on the following consultation information, generate a comprehensive, well-formatted doctor's report in Markdown format.

      CONSULTATION TRANSCRIPT:
      {transcript}

      DOCTOR'S NOTES:
      {doctor_notes}

      APPOINTMENT NOTES:
      {appointment_notes}

      AI-GENERATED SUMMARY:
      {ai_summary}

      Please create a professional medical report in Markdown format with the following structure:

      # Medical Consultation Report

      ## Patient Information
      - Include relevant patient details from the consultation

      ## Consultation Date & Time
      - Document when the consultation occurred

      ## Chief Complaint
      - Primary reason for visit

      ## History of Present Illness (HPI)
      - Detailed narrative of current medical issues
      - Timeline of symptoms
      - Relevant medical history

      ## Physical Examination
      - Vital signs (if mentioned)
      - Examination findings by system

      ## Assessment & Diagnosis
      - Clinical impressions
      - Differential diagnoses if applicable
      - Final diagnosis

      ## Treatment Plan
      - Medications prescribed (with dosage, frequency, duration)
      - Non-pharmacological interventions
      - Lifestyle modifications recommended

      ## Investigations Ordered
      - Laboratory tests
      - Imaging studies
      - Other diagnostic procedures

      ## Follow-up Plan
      - Next appointment date/timeframe
      - Red flag symptoms to watch for
      - When to seek immediate care

      ## Additional Notes
      - Any other relevant clinical information
      - Patient education provided
      - Referrals if any

      Use proper Markdown formatting with headers, bullet points, bold text for emphasis, and tables where appropriate. Make it professional, comprehensive, and suitable for medical records."""

      # Generate Doctor Report
      report_response = client.chat.completions.create(
          model="google/gemini-2.0-flash-exp:free",
          messages=[
              {"role": "system", "content": "You are a medical AI assistant specialized in creating comprehensive medical reports in Markdown format."},
              {"role": "user", "content": report_prompt}
          ],
          temperature=0.3,
          max_tokens=3000
      )

      doctor_report = report_response.choices[0].message.content

      # Save Doctor Report
      with open("doctor_report.md", "w", encoding="utf-8") as f:
          f.write(doctor_report)

      print("Doctor Report generated successfully")
    outputFiles:
      - "doctor_report.md"

  # Task 5: Update Supabase with AI Summary and processing status
  - id: update_consultation_summary
    type: io.kestra.plugin.core.http.Request
    uri: "{{ vars.supabase_url }}/rest/v1/consultations"
    method: PATCH
    headers:
      apikey: "{{ vars.supabase_key }}"
      Authorization: "Bearer {{ vars.supabase_key }}"
      Content-Type: "application/json"
      Prefer: "return=minimal"
    contentType: application/json
    options:
      queryParameters:
        id: "eq.{{ inputs.consultation_id }}"
    body: |
      {
        "ai_summary": "{{ read(outputs.generate_ai_summary.outputFiles['ai_summary.txt']) }}",
        "processing_status": "completed",
        "updated_at": "{{ now() }}"
      }

  # Task 6: Send results to callback webhook
  - id: send_results
    type: io.kestra.plugin.core.http.Request
    uri: "{{ inputs.callback_url }}"
    method: POST
    contentType: application/json
    body: |
      {
        "consultation_id": "{{ inputs.consultation_id }}",
        "ai_summary": "{{ read(outputs.generate_ai_summary.outputFiles['ai_summary.txt']) }}",
        "doctor_report": "{{ read(outputs.generate_doctor_report.outputFiles['doctor_report.md']) }}",
        "status": "completed",
        "processed_at": "{{ now() }}"
      }

triggers:
  - id: webhook_trigger
    type: io.kestra.plugin.core.trigger.Webhook
    key: "{{ vars.webhook_secret_key }}"

errors:
  # Update consultation processing status to failed on error
  - id: update_consultation_failed
    type: io.kestra.plugin.core.http.Request
    uri: "{{ vars.supabase_url }}/rest/v1/consultations"
    method: PATCH
    headers:
      apikey: "{{ vars.supabase_key }}"
      Authorization: "Bearer {{ vars.supabase_key }}"
      Content-Type: "application/json"
      Prefer: "return=minimal"
    contentType: application/json
    options:
      queryParameters:
        id: "eq.{{ inputs.consultation_id }}"
    body: |
      {
        "processing_status": "failed",
        "updated_at": "{{ now() }}"
      }

  # Send error notification to callback webhook
  - id: error_handler
    type: io.kestra.plugin.core.http.Request
    uri: "{{ inputs.callback_url }}"
    method: POST
    contentType: application/json
    body: |
      {
        "consultation_id": "{{ inputs.consultation_id }}",
        "status": "failed",
        "error": "{{ task.error }}",
        "failed_at": "{{ now() }}"
      }

